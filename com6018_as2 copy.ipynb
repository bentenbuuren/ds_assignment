{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, StackingClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image, ImageEnhance, ImageOps, ImageFilter\n",
    "from numpy import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = joblib.load('train.joblib')\n",
    "data_test = joblib.load('eval1.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train images and labels\n",
    "train_images = data_train['data']\n",
    "train_labels = data_train['target']\n",
    "#Test images and labels\n",
    "test_images = data_test['data']\n",
    "test_labels = data_test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hflip(image):\n",
    "    image_aug = ImageOps.mirror(image)\n",
    "    return image_aug\n",
    "\n",
    "def brightness(image1, image2, min_factor=0.5, max_factor=1.5):\n",
    "    enhancer1 = ImageEnhance.Brightness(image1)\n",
    "    enhancer2 = ImageEnhance.Brightness(image2)\n",
    "    factor = np.random.uniform(min_factor, max_factor)\n",
    "    image1_aug = enhancer1.enhance(factor)\n",
    "    image2_aug = enhancer2.enhance(factor)\n",
    "    return image1_aug, image2_aug\n",
    "\n",
    "def contrast(image1, image2, min_factor=0.5, max_factor=1.5):\n",
    "    enhancer1 = ImageEnhance.Contrast(image1)\n",
    "    enhancer2 = ImageEnhance.Contrast(image2)\n",
    "    factor = np.random.uniform(min_factor, max_factor)\n",
    "    image1_aug = enhancer1.enhance(factor)\n",
    "    image2_aug = enhancer2.enhance(factor)\n",
    "    return image1_aug, image2_aug\n",
    "\n",
    "def rotate(image1, image2, angles=15):\n",
    "    angle = np.random.uniform(-angles, angles)\n",
    "    image1_aug = image1.rotate(angle)\n",
    "    image2_aug = image2.rotate(angle)\n",
    "    return image1_aug, image2_aug\n",
    "\n",
    "def vflip(image):\n",
    "    image_aug = ImageOps.flip(image)\n",
    "    return image_aug\n",
    "\n",
    "def edges(image):\n",
    "    image_aug = image.filter(ImageFilter.FIND_EDGES)\n",
    "    return image_aug\n",
    "\n",
    "def blur(image, radius=0.5):\n",
    "    image_aug = image.filter(ImageFilter.GaussianBlur(radius))\n",
    "    return image_aug\n",
    "\n",
    "def invert_colours(image):\n",
    "    image_aug = ImageOps.invert(image)\n",
    "    return image_aug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_images_set(train_images, train_labels, augmentation, augmented_sets):\n",
    "\n",
    "    indices = np.random.choice(len(train_images), size=augmented_sets, replace=False)\n",
    "\n",
    "    augmented_dataset = []\n",
    "    augmented_labels = []\n",
    "\n",
    "    for idx in indices:\n",
    "        pair = train_images[idx]\n",
    "        label = train_labels[idx]\n",
    "        \n",
    "        image1 = Image.fromarray(pair[:2914].reshape(62, 47) * 255).convert(\"L\")\n",
    "        image2 = Image.fromarray(pair[2914:].reshape(62, 47) * 255).convert(\"L\")\n",
    "\n",
    "        # Apply augmentation (e.g., rotate both images by the same angle)\n",
    "        if augmentation in [rotate, brightness, contrast]:\n",
    "            image1_aug, image2_aug = augmentation(image1, image2)\n",
    "        else:\n",
    "            image1_aug = augmentation(image1)\n",
    "            image2_aug = augmentation(image2)\n",
    "\n",
    "\n",
    "        image1_aug_flat = np.array(image1_aug).flatten()\n",
    "        image2_aug_flat = np.array(image2_aug).flatten()\n",
    "        \n",
    "        augmented_pair = np.hstack([image1_aug_flat, image2_aug_flat])\n",
    "        augmented_dataset.append(augmented_pair)\n",
    "        augmented_labels.append(label)\n",
    "    \n",
    "    # Convert lists to numpy arrays\n",
    "    augmented_dataset = np.array(augmented_dataset)\n",
    "    augmented_labels = np.array(augmented_labels)\n",
    "    return augmented_dataset, augmented_labels\n",
    "\n",
    "# augmented_dataset_vflip, augmented_labels_vflip = augment_images_set(train_images, train_labels,vflip, 300)\n",
    "augmented_dataset_hflip, augmented_labels_hflip = augment_images_set(train_images, train_labels,hflip, 200)\n",
    "augmented_dataset_brightness, augmented_labels_brightness = augment_images_set(train_images, train_labels,brightness, 300)\n",
    "augmented_dataset_contrast, augmented_labels_contrast = augment_images_set(train_images, train_labels,contrast, 300)\n",
    "# augmented_dataset_edges, augmented_labels_edges = augment_images_set(train_images, train_labels,edges, 300)\n",
    "augmented_dataset_rotate, augmented_labels_rotate = augment_images_set(train_images, train_labels,rotate, 200)\n",
    "# augmented_dataset_blur, augmented_labels_blur = augment_images_set(train_images, train_labels,blur, 300)\n",
    "# augmented_dataset_invert_colours, augmented_labels_invert_colours = augment_images_set(train_images, train_labels,invert_colours, 300)\n",
    "\n",
    "augmented_dataset_combined = np.vstack([\n",
    "    # augmented_dataset_vflip,\n",
    "    augmented_dataset_hflip,\n",
    "    augmented_dataset_brightness,\n",
    "    augmented_dataset_contrast,\n",
    "    # augmented_dataset_edges,\n",
    "    augmented_dataset_rotate,\n",
    "    # augmented_dataset_blur,\n",
    "    # augmented_dataset_invert_colours\n",
    "])\n",
    "\n",
    "augmented_labels_combined = np.hstack([\n",
    "    # augmented_labels_vflip,\n",
    "    augmented_labels_hflip,\n",
    "    augmented_labels_brightness,\n",
    "    augmented_labels_contrast,\n",
    "    # augmented_labels_edges,\n",
    "    augmented_labels_rotate,\n",
    "    # augmented_labels_blur,\n",
    "    # augmented_labels_invert_colours\n",
    "])\n",
    "\n",
    "train_images_aug = np.vstack([train_images, augmented_dataset_combined])\n",
    "train_labels_aug = np.hstack([train_labels, augmented_labels_combined])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the images into two parts\n",
    "train_images1_aug = train_images_aug[:, :5828 // 2]\n",
    "train_images2_aug = train_images_aug[:, 5828 // 2:]\n",
    "# Pixel + euc distance\n",
    "train_pixel_diff_aug = np.abs(train_images1_aug - train_images2_aug)\n",
    "train_euc_dist_aug = np.linalg.norm(train_images1_aug - train_images1_aug, axis=1).reshape(-1, 1)\n",
    "#feature stacking\n",
    "train_features_aug = np.hstack([train_pixel_diff_aug, train_euc_dist_aug])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data Prep\n",
    "test_images1 = test_images[:, :5828 // 2]\n",
    "test_images2 = test_images[:, 5828 // 2:]\n",
    "test_pixel_diff = np.abs(test_images1 - test_images2)\n",
    "test_euc_dist = np.linalg.norm(test_images1 - test_images2, axis=1).reshape(-1, 1)\n",
    "test_features = np.hstack([test_pixel_diff, test_euc_dist])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardise + PCA of Feature Engineer Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distance PCA\n",
    "#Standardise\n",
    "scaler = StandardScaler()\n",
    "train_features_scaled_aug = scaler.fit_transform(train_features_aug)\n",
    "test_features_scaled = scaler.transform(test_features)\n",
    "#PCA\n",
    "pca = PCA(n_components=50)\n",
    "train_features_pca_aug = pca.fit_transform(train_features_scaled_aug)\n",
    "test_features_pca = pca.transform(test_features_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "Best Parameters: {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "Best Cross-Validation Accuracy: 0.6043749999999999\n",
      "Training Accuracy: 76.47%\n",
      "Testing Accuracy: 66.40%\n"
     ]
    }
   ],
   "source": [
    "#SVM pipeline Augmented and Features Engineered\n",
    "# Define the parameter grid\n",
    "param_grid_svm = {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': [0.1, 1, 10, 100, 1000],\n",
    "        'gamma': [0.001, 0.01, 0.1, 1],\n",
    "    }\n",
    "svm = SVC(random_state=1)\n",
    "# Perform Grid Search\n",
    "grid_search_svm = GridSearchCV(estimator=svm, param_grid=param_grid_svm, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search_svm.fit(train_features_pca_aug, train_labels_aug)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best Parameters:\", grid_search_svm.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search_svm.best_score_)\n",
    "\n",
    "#SVM result Features Engineered\n",
    "y_train_pred = grid_search_svm.best_estimator_.predict(train_features_pca_aug)\n",
    "train_accuracy = accuracy_score(train_labels_aug, y_train_pred)\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "y_test_pred = grid_search_svm.best_estimator_.predict(test_features_pca)\n",
    "test_accuracy = accuracy_score(test_labels, y_test_pred)\n",
    "print(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best Parameters: {'max_depth': 5, 'min_samples_leaf': 20, 'min_samples_split': 10, 'n_estimators': 200}\n",
      "Best Cross-Validation Accuracy: 0.61875\n",
      "Training Accuracy: 74.53%\n",
      "Testing Accuracy: 67.00%\n"
     ]
    }
   ],
   "source": [
    "# Random Forest pipeline Aug+features\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [4, 5],\n",
    "    'min_samples_split': [10, 15, 20],\n",
    "    'min_samples_leaf': [10, 15, 20]\n",
    "}\n",
    "rf = RandomForestClassifier(random_state=1)\n",
    "# Perform Grid Search\n",
    "grid_search_rf = GridSearchCV(estimator=rf, param_grid=param_grid_rf, cv=5, verbose=1, n_jobs=-1)\n",
    "grid_search_rf.fit(train_features_pca_aug, train_labels_aug)\n",
    "\n",
    "# Best parameters and score\n",
    "print(\"Best Parameters:\", grid_search_rf.best_params_)\n",
    "print(\"Best Cross-Validation Accuracy:\", grid_search_rf.best_score_)\n",
    "\n",
    "#RF Aug+Features\n",
    "y_train_pred = grid_search_rf.best_estimator_.predict(train_features_pca_aug)\n",
    "train_accuracy = accuracy_score(train_labels_aug, y_train_pred)\n",
    "print(f\"Training Accuracy: {train_accuracy * 100:.2f}%\")\n",
    "\n",
    "y_test_pred = grid_search_rf.best_estimator_.predict(test_features_pca)\n",
    "test_accuracy = accuracy_score(test_labels, y_test_pred)\n",
    "print(f\"Testing Accuracy: {test_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Stacking Classifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 11 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    0.3s remaining:    0.5s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=-1)]: Done   2 out of   5 | elapsed:    1.1s remaining:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking Classifier Train Accuracy: 78.12%\n",
      "Stacking Classifier Test Accuracy: 66.40%\n"
     ]
    }
   ],
   "source": [
    "# Best parameters from Grid Search\n",
    "best_rf_params = grid_search_rf.best_params_\n",
    "best_svm_params = grid_search_svm.best_params_\n",
    "\n",
    "# Define base models with best parameters\n",
    "rf_best = RandomForestClassifier(**best_rf_params, random_state=1)\n",
    "svm_best = SVC(**best_svm_params, random_state=1)\n",
    "\n",
    "# Define the meta-classifier\n",
    "meta_classifier = LogisticRegression(random_state=1)\n",
    "\n",
    "# Create the Stacking Classifier\n",
    "stacking_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('rf', rf_best),\n",
    "        ('svm', svm_best)\n",
    "    ],\n",
    "    final_estimator=meta_classifier,\n",
    "    cv=5,\n",
    "    n_jobs=-1, \n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Train the Stacking Classifier\n",
    "print(\"Training Stacking Classifier\")\n",
    "stacking_clf.fit(train_features_pca_aug, train_labels_aug)\n",
    "\n",
    "# Evaluate on Train Data\n",
    "train_y_pred = stacking_clf.predict(train_features_pca_aug)\n",
    "train_accuracy = accuracy_score(train_labels_aug, train_y_pred)\n",
    "print(f\"Stacking Classifier Train Accuracy: {train_accuracy*100:.2f}%\")\n",
    "\n",
    "# Evaluate on Test Data\n",
    "y_pred = stacking_clf.predict(test_features_pca)\n",
    "test_accuracy = accuracy_score(test_labels, y_pred)\n",
    "print(f\"Stacking Classifier Test Accuracy: {test_accuracy*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "com6018",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
